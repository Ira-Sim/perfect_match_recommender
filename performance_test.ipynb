{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch \n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,f1_score\n",
    "import torch.nn as nn\n",
    "from eval import predict,PerfectMatch,AGE_TO_INDEX,GENDER_TO_INDEX,load_checkpoint\n",
    "\n",
    "device = torch.device('cuda' if True and torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "DATA_DIR =r'C:\\Users\\vi04wecu\\Desktop\\Hackbay\\processed_data'\n",
    "test_df = pd.read_excel(os.path.join(DATA_DIR, 'hackbay_test_dataset.xlsx'))\n",
    "test_labels = pd.read_csv(os.path.join(r'C:\\Users\\vi04wecu\\Desktop\\Hackbay', 'test_with_labels.csv'))\n",
    "\n",
    "MAX_SEQ_LEN = 512\n",
    "\n",
    "GENDER_TO_INDEX = {\n",
    "    'maennlich':0,\n",
    "    'weiblich':1\n",
    "}\n",
    "AGE_TO_INDEX = {\n",
    "'16 bis 17 Jahre':0,\n",
    "'50 bis 54 Jahre':1,\n",
    "'65 bis 69 Jahre':2, \n",
    "'25 bis 29 Jahre':3,\n",
    "'14 bis 15 Jahre':4,\n",
    "'55 bis 59 Jahre':5,\n",
    "'10 bis 13 Jahre':6,\n",
    "'75 und mehr Jahre':7,\n",
    "'60 bis 64 Jahre':8,\n",
    "'35 bis 39 Jahre':9,\n",
    "'40 bis 44 Jahre':10,\n",
    "'70 bis 74 Jahre':11,\n",
    "'30 bis 34 Jahre':12,\n",
    "'45 bis 49 Jahre':13,\n",
    "'18 bis 19 Jahre':14,\n",
    "'20 bis 24 Jahre':15\n",
    "}\n",
    "\n",
    "def preprocess_text(text):\n",
    "  # preprocess text.\n",
    "  # remove non-alphanumeric characters\n",
    "  # keep numbers\n",
    "  if text == text:\n",
    "    text = re.sub(r'\\W+',' ',text,flags=re.UNICODE)\n",
    "    text = re.sub(r'[\\n\\t\\r]',' ',text)            # delete linebreakers on windows, linux, mac?\n",
    "    # trim to required length\n",
    "    text = text[:MAX_SEQ_LEN]\n",
    "    return text\n",
    "\n",
    "test_labels['age'] = test_labels['age'].apply(lambda x:AGE_TO_INDEX[x])\n",
    "test_labels['gender'] = test_labels['gender'].apply(lambda x:GENDER_TO_INDEX[x])\n",
    "test_df['text'] =  test_df['title']+ ' '+ test_df['text']\n",
    "\n",
    "test_df = test_df.dropna(subset=['text'])\n",
    "print(test_df.shape)  \n",
    "\n",
    "test_df['text'] = test_df['text'].apply(lambda x: preprocess_text(' '.join(x.split('|'))))\n",
    "test_df.drop(columns= ['title', 'keywords', 'colors', 'number_of_images'], inplace=True)\n",
    "\n",
    " \n",
    "def load_params():\n",
    "    model = PerfectMatch().to(device)\n",
    "    model_path = 'perfect_match_model.pt'\n",
    "    if os.path.exists(model_path):\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "        model,optimizer = load_checkpoint(model_path, model, optimizer)\n",
    "\n",
    "    model = model.to(device)\n",
    "    # Define tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased')\n",
    "    \n",
    "    # Load (and possibly transform) our dataset which will be used for making recommendations\n",
    "    recommendation_df = pd.read_excel('hackbay_recommendations.xlsx')\n",
    "    return model,tokenizer,recommendation_df\n",
    "\n",
    "model, tokenizer = load_params()   \n",
    "\n",
    "test_df['prediction'] = ''\n",
    "for i in range(test_df.shape[0]):\n",
    "        test_df['prediction'][i] = predict( test_df['text'][i], model, tokenizer)\n",
    "        \n",
    "        \n",
    "        \n",
    "test_pred_out = pd.merge(test_df, test_labels, how= 'inner')\n",
    "\n",
    "def compute_metrics(labels,probs):\n",
    "  softmax = nn.Softmax(dim=1)\n",
    "  preds =softmax(probs)\n",
    "  acc_preds = torch.argmax(preds,dim=1).squeeze().cpu().tolist()\n",
    "  labels = labels.squeeze().cpu().tolist()\n",
    "  acc = accuracy_score(labels,acc_preds)\n",
    "  f1 = f1_score(labels,acc_preds,average='weighted')\n",
    "  return {'f1': f1, 'accuracy':acc}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
